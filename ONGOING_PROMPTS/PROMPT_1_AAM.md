# AAM Agent — Trifecta Flow Fixes

## Your Role

You are the AAM (Adaptive API Mesh) module. You own two outbound flows:

- **Path 1 — Structure Path (AAM → DCL):** You publish pipe schemas via `/export-pipes` so DCL knows what data to expect. This is metadata only — no data rows.
- **Path 2 — Instruction Path (AAM → Farm):** You dispatch Runner manifests (JobManifest) to Farm, telling it what to extract, from where, and where to deliver the data.

You do NOT push data to DCL. You do NOT execute extraction. You are the architect who draws blueprints (Path 1) and writes job orders (Path 2).

---

## Change 1: Fix Export pipe_id (Path 1)

**CURRENT BUG:** The export uses `candidate_id` as `pipe_id` in the connections list. This breaks DCL's late-binding join because Farm pushes data tagged with the real `DeclaredPipe.pipe_id`.

**FIX:** When building `DCLConnectionSchema`, use the resolved `DeclaredPipe.pipe_id` (via `candidate.matched_pipe_id`) as the primary `pipe_id`. Demote `candidate_id` to a separate field for provenance tracking.

### Updated Export Schema (DCLExportResponse)

```
DCLExportResponse
├── aod_run_id: string?
├── timestamp: string (ISO + Z)
├── source: "aam"
├── total_connections: int
└── fabric_planes: list[DCLFabricPlane]
    ├── plane_type: string
    ├── vendor: string
    ├── connection_count: int
    ├── health: string
    └── connections: list[DCLConnectionSchema]
        ├── pipe_id: string          ⚠️ CHANGE: use DeclaredPipe.pipe_id (via matched_pipe_id)
        ├── candidate_id: string     ✨ NEW: preserve original candidate_id for provenance
        ├── source_name: string
        ├── vendor: string
        ├── category: string
        ├── governance_status: string?
        ├── fields: list[string]     (5-level cascade, unchanged)
        ├── entity_scope: string?    ✨ NEW: from pipe inference
        ├── identity_keys: list?     ✨ NEW: from pipe inference
        ├── transport_kind: string?  ✨ NEW: from pipe inference
        ├── modality: string?        ✨ NEW: from pipe inference
        ├── change_semantics: str?   ✨ NEW: from pipe inference
        ├── health: string
        ├── last_sync: string?
        ├── asset_key: string
        └── aod_asset_id: string?
```

---

## Change 2: Dispatch Runner Manifest to Farm (Path 2)

**CURRENT BUG:** `build_manifest()` constructs a JobManifest and the runner executes it directly, pushing simulated data to DCL. AAM should not execute data extraction — it should dispatch the manifest to Farm and let Farm handle extraction and delivery.

**FIX:** Two changes:
1. **Dispatch routing:** After building the manifest, POST it to Farm's intake endpoint (e.g., `POST /api/farm/manifest-intake`) instead of executing the runner locally.
2. **Keep target.dcl_url as-is:** The manifest's `target.dcl_url` still points to DCL's `/ingest` — this tells Farm where to deliver the data. The manifest is an instruction to Farm, not a self-executing job.

### JobManifest Schema (what Farm receives)

```
JobManifest
├── manifest_version: "1.0"
├── run_id: string                    (generated by AAM)
├── farm_verification: bool
├── source: SourceSpec
│   ├── pipe_id: string               (DeclaredPipe.pipe_id — MUST match export)
│   ├── system: string                (vendor name)
│   ├── adapter: string               (rest_api|jdbc|kafka|ipaas|webhook)
│   ├── endpoint_ref: dict            (opaque connection info)
│   ├── credentials_ref: string?      (vault URI, never plaintext)
│   └── query: string?                (extraction filter)
├── transform: TransformSpec?          (populate from pipe inference)
│   ├── schema_map: dict              (source_field → {target, unit, scale, dim})
│   ├── grain: string?                (quarter|month|day)
│   ├── period_field: string?
│   └── period_format: string?        (YYYY-Qq, etc.)
├── target: TargetSpec
│   ├── dcl_url: string               (DCL's /ingest — tells Farm WHERE to deliver data)
│   ├── auth_token_ref: string?
│   ├── tenant_id: string?
│   └── snapshot_name: string?
├── provenance: dict
│   ├── run_timestamp: string
│   └── triggered_by: string
└── limits: RunLimits
    ├── max_rows: int (100000)
    ├── timeout_seconds: int (300)
    └── retry_count: int (2)
```

---

## Critical Contract: pipe_id Alignment

The `pipe_id` in `source.pipe_id` of the JobManifest **MUST** be the same `DeclaredPipe.pipe_id` used in the Export's `connections[].pipe_id`. This is the join key that makes the late-binding architecture work. DCL will JOIN Structure (from Export) with Content (from Farm) on this key.

---

## RACI Fields You Own (Pipe Inference)

Per the RACI matrix, AAM is A/R for all pipe inference. Populate these in both the Export schema AND the Runner manifest where applicable:

| Inference | Export Field | Manifest Field | Source |
|-----------|-------------|----------------|--------|
| Fabric Plane | Already in fabric_planes[] | N/A (structural) | fabric_planes DB |
| Entity Scope | entity_scope (NEW) | N/A | infer_entity_scope() |
| Identity Keys | identity_keys (NEW) | N/A | infer_identity_keys() |
| Transport Kind | transport_kind (NEW) | source.adapter | infer_transport_kind() |
| Modality | modality (NEW) | N/A | infer_modality() |
| Change Semantics | change_semantics (NEW) | N/A | infer_change_semantics() |
| Schema Map | fields[] (existing) | transform.schema_map | 5-level cascade + inference |
